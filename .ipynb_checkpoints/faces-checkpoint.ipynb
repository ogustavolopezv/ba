{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SQLContext, SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.mllib.linalg import Vectors\n",
    "from pyspark.mllib.linalg.distributed import RowMatrix\n",
    "from pyspark.mllib.util import MLUtils\n",
    "from pyspark.mllib.feature import LabeledPoint\n",
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics\n",
    "from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.feature import PCA, StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spark Session\n",
    "appName = \"faces\"\n",
    "master = \"local\"\n",
    "\n",
    "conf = (SparkConf()\n",
    "    .set(\"spark.driver.maxResultSize\", \"8g\")\n",
    "    .set(\"spark.driver.memory\", \"16g\") )\n",
    "\n",
    "sc = SparkContext(master, appName, conf = conf)\n",
    "sqlContext = SQLContext(sc)\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(appName) \\\n",
    "    .master(master) \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy = 0.9320388349514563\n"
     ]
    }
   ],
   "source": [
    "# Inbound\n",
    "raw = spark.read.csv(\"raw/rostros_db_e1.csv\")\n",
    "raw = raw.withColumnRenamed(\"_c576\", \"label\")\n",
    "raw = raw.withColumn(\"label\", F.regexp_replace(F.col(\"label\"), \"no_rostro\", \"0\"))\n",
    "raw = raw.withColumn(\"label\", F.regexp_replace(F.col(\"label\"), \"rostro\", \"1\"))\n",
    "# raw.show(1, vertical = True)\n",
    "\n",
    "faces = raw.filter(F.col(\"label\") == \"1\")\n",
    "faces = faces.drop(\"label\")\n",
    "# faces.show(1, vertical = True)\n",
    "\n",
    "not_faces = raw.filter(F.col(\"label\") == \"0\")\n",
    "# not_faces.show(1, vertical = True)\n",
    "\n",
    "# SVMLIB format\n",
    "!rm -r libsvm/faces\n",
    "r = raw.rdd.map(lambda line:LabeledPoint(line[-1], Vectors.dense(line[0:575])))\n",
    "MLUtils.saveAsLibSVMFile(r, \"libsvm/faces/\")\n",
    "faces_libsvm = spark.read.format(\"libsvm\").load(\"libsvm/faces/\")\n",
    "# faces_libsvm.show(truncate = False)\n",
    "\n",
    "# PCA\n",
    "pca = PCA(k = 15, inputCol = \"features\", outputCol = \"pca_features\")\n",
    "model = pca.fit(faces_libsvm)\n",
    "faces_libsvm = model.transform(faces_libsvm)#.select(\"pca_features\")\n",
    "# faces_libsvm.show(1, truncate = False)\n",
    "\n",
    "# Mean face\n",
    "mean_face = faces.select(*[F.mean(c).alias(c) for c in faces.columns])\n",
    "mean_face_array = np.array(mean_face.collect()).astype(np.uint8).reshape(-1)\n",
    "mean_face_array = mean_face_array.reshape(24, 24)\n",
    "img = Image.fromarray(mean_face_array)\n",
    "img.save('mean_face.png')\n",
    "\n",
    "# Normalize\n",
    "scaler = StandardScaler(inputCol = \"pca_features\", outputCol = \"norm_features\",\n",
    "                        withStd = True, withMean = True)\n",
    "scaler_model = scaler.fit(faces_libsvm)\n",
    "faces_libsvm = scaler_model.transform(faces_libsvm)\n",
    "faces_libsvm = faces_libsvm.select(\"label\", \"pca_features\")\n",
    "faces_libsvm = faces_libsvm.withColumnRenamed(\"pca_features\", \"features\")\n",
    "# faces_libsvm.show(truncate = False)\n",
    "\n",
    "# Classifier (MLP)\n",
    "data = faces_libsvm\n",
    "# Train and test\n",
    "splits = data.randomSplit([0.6, 0.4], 1234)\n",
    "train = splits[0]\n",
    "test = splits[1]\n",
    "# Define network\n",
    "layers = [15, 10, 8, 2]\n",
    "trainer = MultilayerPerceptronClassifier(maxIter = 100, layers = layers, \n",
    "                                         blockSize = 128, seed = 1234)\n",
    "# Training.\n",
    "model = trainer.fit(train)\n",
    "# Accuracy of test\n",
    "result = model.transform(test)\n",
    "predictionAndLabels = result.select(\"prediction\", \"label\")\n",
    "evaluator = MulticlassClassificationEvaluator(metricName = \"accuracy\")\n",
    "print(\"Test set accuracy = \" + str(evaluator.evaluate(predictionAndLabels)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
